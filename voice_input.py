#!/usr/bin/env python3
"""
è¯­éŸ³è¾“å…¥å·¥å…· - åŸºäº OpenAI Whisper ç¦»çº¿è¯†åˆ«

ä¸‰ç§è¿è¡Œæ¨¡å¼:
  python voice_input.py          # æ™®é€šæ¨¡å¼ (4-5ç§’å¯åŠ¨)
  python voice_input.py --daemon # å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ (å¸¸é©»åå°)
  python voice_input.py --trigger # è§¦å‘å®ˆæŠ¤è¿›ç¨‹ (<0.5ç§’å¯åŠ¨)

å¿«æ·é”®å»ºè®®: Super+V
"""

import whisper
import pyaudio
import wave
import tempfile
import os
import subprocess
import sys
import time
import numpy as np
import socket
import json
import signal
import select
import argparse

# å°è¯•å¯¼å…¥ Tkinter
USE_TKINTER = False
try:
    import tkinter as tk
    from tkinter import ttk
    USE_TKINTER = True
except ImportError:
    USE_TKINTER = False

# å°è¯•å¯¼å…¥ OpenCC ç”¨äºç¹ç®€è½¬æ¢
try:
    from opencc import OpenCC
    OPENCC_AVAILABLE = True
except ImportError:
    OPENCC_AVAILABLE = False

# ========== é…ç½®å‚æ•° ==========
WHISPER_MODEL = "base"  # å¯é€‰: tiny, base, small, medium, large
LANGUAGE = "zh"         # ä¸­æ–‡è¯†åˆ«
SAMPLE_RATE = 16000     # é‡‡æ ·ç‡
CHANNELS = 1            # å•å£°é“
CHUNK = 1024            # éŸ³é¢‘å—å¤§å°
RECORD_SECONDS = 60     # æœ€é•¿å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
SILENCE_THRESHOLD = 800 # é™éŸ³é˜ˆå€¼ï¼ˆæ™®é€šæ¨¡å¼ï¼‰
SILENCE_THRESHOLD_DAEMON = 600  # é™éŸ³é˜ˆå€¼ï¼ˆå®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ï¼‰
SILENCE_DURATION = 2.0  # é™éŸ³æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰åˆ¤å®šä¸ºç»“æŸ

# Socket é…ç½®
SOCKET_PATH = "/tmp/voice_input_daemon.sock"

# UI é…ç½®å¸¸é‡
WINDOW_WIDTH = 700
WINDOW_HEIGHT = 300
WINDOW_HEIGHT_BORDERLESS = 280
FONT_FAMILY = "Helvetica"
FONT_SIZE_TITLE = 16
FONT_SIZE_VOLUME = 11
FONT_SIZE_TEXT = 12
FONT_SIZE_TIP = 10
COLOR_BG = '#f8f8f8'
COLOR_BORDER = '#d0d0d0'
COLOR_TEXT_PRIMARY = '#1d1d1f'
COLOR_TEXT_SECONDARY = '#86868b'
COLOR_SUCCESS = '#34c759'
COLOR_ERROR = '#ff3b30'
COLOR_PROGRESS_BG = '#e5e5e7'
VOLUME_BAR_LENGTH = 500
VOLUME_BAR_THICKNESS = 18
AUTO_CLOSE_DELAY = 1000  # çª—å£è‡ªåŠ¨å…³é—­å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰


# ========== UI ç»„ä»¶ ==========
class VoiceInputUI:
    """è¯­éŸ³è¾“å…¥ UI ç•Œé¢ï¼ˆè‡ªåŠ¨é€‰æ‹© Tkinter æˆ–ç»ˆç«¯æ¨¡å¼ï¼‰"""

    def __init__(self, mode="auto", title="è¯­éŸ³è¾“å…¥", borderless=False, stop_callback=None):
        self.title = title
        self.borderless = borderless
        self.stop_callback = stop_callback

        # æ”¯æŒç¯å¢ƒå˜é‡æ§åˆ¶ UI æ¨¡å¼
        env_mode = os.getenv('VOICE_INPUT_UI_MODE', '').lower()
        if env_mode in ['gui', 'terminal']:
            mode = env_mode

        # è‡ªåŠ¨é€‰æ‹©æ¨¡å¼
        if mode == "auto":
            self.mode = "gui" if USE_TKINTER else "terminal"
        elif mode == "gui" and not USE_TKINTER:
            print("âš ï¸  Tkinter ä¸å¯ç”¨ï¼Œé™çº§ä¸ºç»ˆç«¯æ¨¡å¼")
            self.mode = "terminal"
        else:
            self.mode = mode

        # åˆå§‹åŒ–å¯¹åº”çš„ UI
        if self.mode == "gui":
            self._init_gui()
        else:
            self._init_terminal()

    def _init_gui(self):
        """åˆå§‹åŒ– Tkinter GUI"""
        self.root = tk.Tk()
        self.root.title(f"ğŸ¤ {self.title}")

        # çª—å£è®¾ç½®
        self.root.attributes('-topmost', True)
        self.root.resizable(False, False)

        # æ— è¾¹æ¡†æ¨¡å¼
        if self.borderless:
            self.root.overrideredirect(True)
            self.root.configure(bg=COLOR_BORDER)

        # å±…ä¸­æ˜¾ç¤º
        window_width = WINDOW_WIDTH
        window_height = WINDOW_HEIGHT if not self.borderless else WINDOW_HEIGHT_BORDERLESS
        screen_width = self.root.winfo_screenwidth()
        screen_height = self.root.winfo_screenheight()
        x = (screen_width - window_width) // 2
        y = (screen_height - window_height) // 2
        self.root.geometry(f"{window_width}x{window_height}+{x}+{y}")

        # å¼ºåˆ¶è·å–ç„¦ç‚¹
        self.root.update()
        self.root.lift()
        self.root.focus_force()

        # ç»‘å®š Esc é”®åœæ­¢å½•éŸ³
        if self.stop_callback:
            self.root.bind('<Escape>', lambda e: self.stop_callback())
            self.root.bind('<Control-c>', lambda e: self.stop_callback())

        # è®¾ç½®æ ·å¼
        style = ttk.Style()
        style.theme_use('clam')

        # åˆ›å»ºå†…å®¹å®¹å™¨
        if self.borderless:
            content_frame = tk.Frame(self.root, bg=COLOR_BG, highlightthickness=0)
            content_frame.pack(fill=tk.BOTH, expand=True, padx=2, pady=2)
            parent = content_frame
        else:
            parent = self.root
            self.root.configure(bg=COLOR_BG)

        # çŠ¶æ€æ ‡ç­¾
        self.status_label = tk.Label(
            parent,
            text="ğŸ¤ æ­£åœ¨å½•éŸ³...",
            font=(FONT_FAMILY, FONT_SIZE_TITLE),
            fg=COLOR_TEXT_PRIMARY,
            bg=COLOR_BG,
            wraplength=660,
            justify=tk.CENTER
        )
        self.status_label.pack(pady=18)

        # éŸ³é‡æ¡å®¹å™¨
        volume_frame = tk.Frame(parent, bg=COLOR_BG)
        volume_frame.pack(pady=14)

        tk.Label(
            volume_frame,
            text="éŸ³é‡",
            font=(FONT_FAMILY, FONT_SIZE_VOLUME),
            fg=COLOR_TEXT_SECONDARY,
            bg=COLOR_BG,
            width=4
        ).pack(side=tk.LEFT, padx=(20, 10))

        # éŸ³é‡è¿›åº¦æ¡
        self.volume_bar = ttk.Progressbar(
            volume_frame,
            length=VOLUME_BAR_LENGTH,
            mode='determinate',
            style='Apple.Horizontal.TProgressbar'
        )
        self.volume_bar.pack(side=tk.LEFT, padx=10)

        # é…ç½®è¿›åº¦æ¡æ ·å¼
        style.configure(
            'Apple.Horizontal.TProgressbar',
            troughcolor=COLOR_PROGRESS_BG,
            background=COLOR_SUCCESS,
            borderwidth=0,
            thickness=VOLUME_BAR_THICKNESS
        )

        # ç™¾åˆ†æ¯”æ ‡ç­¾
        self.volume_label = tk.Label(
            volume_frame,
            text="0%",
            font=(FONT_FAMILY, FONT_SIZE_VOLUME),
            width=8,
            anchor=tk.W,
            fg=COLOR_SUCCESS,
            bg=COLOR_BG
        )
        self.volume_label.pack(side=tk.LEFT, padx=(10, 25))

        # è¯†åˆ«æ–‡æœ¬
        self.text_label = tk.Label(
            parent,
            text="",
            font=(FONT_FAMILY, FONT_SIZE_TEXT),
            wraplength=660,
            fg=COLOR_TEXT_PRIMARY,
            bg=COLOR_BG,
            justify=tk.CENTER
        )
        self.text_label.pack(pady=14)

        # æç¤ºæ–‡æœ¬
        tip_text = "æŒ‰ Esc æˆ– Ctrl+C åœæ­¢å½•éŸ³" if self.stop_callback else "æŒ‰ Ctrl+C åœæ­¢å½•éŸ³"
        self.tip_label = tk.Label(
            parent,
            text=tip_text,
            font=(FONT_FAMILY, FONT_SIZE_TIP),
            fg=COLOR_TEXT_SECONDARY,
            bg=COLOR_BG
        )
        self.tip_label.pack(pady=10)

        # çª—å£å…³é—­æ—¶çš„å¤„ç†
        self.root.protocol("WM_DELETE_WINDOW", self._on_close)

    def _init_terminal(self):
        """åˆå§‹åŒ–ç»ˆç«¯æ¨¡å¼"""
        print(f"ğŸ¤ {self.title}")
        print("=" * 50)

    def update_volume(self, volume):
        """æ›´æ–°éŸ³é‡æ˜¾ç¤º"""
        if self.mode == "gui":
            try:
                self.volume_bar['value'] = volume
                self.volume_label.config(text=f"{int(volume)}%")
                self.root.update()
            except:
                pass
        else:
            bar_length = 30
            filled = int(volume / 100 * bar_length)
            bar = "â–“" * filled + "â–‘" * (bar_length - filled)
            print(f"\réŸ³é‡: {bar} {int(volume):3d}%", end="", flush=True)

    def update_text(self, text):
        """æ›´æ–°è¯†åˆ«æ–‡æœ¬"""
        if self.mode == "gui":
            try:
                self.text_label.config(text=text)
                self.root.update()
            except:
                pass
        else:
            print(f"\nè¯†åˆ«ä¸­: {text}")

    def show_status(self, status, color=None):
        """æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯"""
        if self.mode == "gui":
            try:
                self.status_label.config(text=status)
                if color:
                    self.status_label.config(fg=color)
                self.root.update()
            except:
                pass
        else:
            print(f"\n{status}")

    def show_result(self, text, success=True):
        """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
        if self.mode == "gui":
            try:
                if success:
                    self.status_label.config(text="âœ… è¯†åˆ«å®Œæˆ", fg=COLOR_SUCCESS)
                    self.text_label.config(text=text, fg=COLOR_TEXT_PRIMARY)
                else:
                    self.status_label.config(text="âŒ è¯†åˆ«å¤±è´¥", fg=COLOR_ERROR)
                    self.text_label.config(text=text, fg=COLOR_ERROR)

                delay_seconds = AUTO_CLOSE_DELAY / 1000
                self.tip_label.config(text=f"çª—å£å°†åœ¨ {delay_seconds:.0f} ç§’åè‡ªåŠ¨å…³é—­...", fg=COLOR_TEXT_SECONDARY)
                self.root.update()

                # è‡ªåŠ¨å…³é—­
                self.root.after(AUTO_CLOSE_DELAY, self.close)
            except:
                pass
        else:
            if success:
                print(f"\n\nâœ… è¯†åˆ«å®Œæˆ\nç»“æœ: {text}")
            else:
                print(f"\n\nâŒ è¯†åˆ«å¤±è´¥\né”™è¯¯: {text}")

    def show_error(self, error_msg):
        """æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯"""
        self.show_result(error_msg, success=False)

    def _on_close(self):
        """çª—å£å…³é—­æ—¶çš„å¤„ç†"""
        try:
            self.root.quit()
            self.root.destroy()
        except:
            pass
        os._exit(0)

    def close(self):
        """å…³é—­ UI"""
        if self.mode == "gui":
            try:
                self.root.quit()
                self.root.destroy()
            except:
                pass
        else:
            print("\n" + "=" * 50)


# ========== æ™®é€šæ¨¡å¼ ==========
class VoiceInputNormal:
    """æ™®é€šæ¨¡å¼ - æ¯æ¬¡å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹"""

    def __init__(self):
        # åˆ›å»º UI
        self.ui = VoiceInputUI(mode="auto", title="è¯­éŸ³è¾“å…¥ (ç¦»çº¿)", borderless=True)

        self.ui.show_status("â³ æ­£åœ¨åŠ è½½æ¨¡å‹...")
        print("æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹...")
        self.model = whisper.load_model(WHISPER_MODEL)
        print(f"æ¨¡å‹åŠ è½½å®Œæˆ: {WHISPER_MODEL}")

        # åˆå§‹åŒ–ç¹ç®€è½¬æ¢å™¨
        if OPENCC_AVAILABLE:
            self.cc = OpenCC('t2s')
            print("ç¹ç®€è½¬æ¢: å·²å¯ç”¨")
        else:
            self.cc = None

        self.ui.show_status("ğŸ¤ æ­£åœ¨å½•éŸ³...")

    def record_audio(self, filename):
        """å½•åˆ¶éŸ³é¢‘ï¼Œæ£€æµ‹é™éŸ³è‡ªåŠ¨åœæ­¢"""
        audio = pyaudio.PyAudio()

        stream = audio.open(
            format=pyaudio.paInt16,
            channels=CHANNELS,
            rate=SAMPLE_RATE,
            input=True,
            frames_per_buffer=CHUNK
        )

        print(f"\nğŸ¤ å¼€å§‹å½•éŸ³... (è¯´è¯ååœé¡¿{SILENCE_DURATION}ç§’è‡ªåŠ¨ç»“æŸï¼Œæœ€é•¿{RECORD_SECONDS}ç§’)")

        frames = []
        silent_chunks = 0
        max_silent_chunks = int(SILENCE_DURATION * SAMPLE_RATE / CHUNK)
        started_speaking = False

        for i in range(0, int(SAMPLE_RATE / CHUNK * RECORD_SECONDS)):
            data = stream.read(CHUNK)
            frames.append(data)

            audio_data = np.frombuffer(data, dtype=np.int16)
            volume = np.abs(audio_data).mean()

            # æ›´æ–° UI éŸ³é‡æ˜¾ç¤º
            volume_percent = min(100, (volume / 3000) * 100)
            self.ui.update_volume(volume_percent)

            if volume > SILENCE_THRESHOLD:
                if not started_speaking:
                    print("\nâœ“ æ£€æµ‹åˆ°å£°éŸ³ï¼Œå¼€å§‹è®°å½•...")
                    self.ui.show_status("ğŸ¤ æ­£åœ¨å½•éŸ³... (æ£€æµ‹åˆ°å£°éŸ³)")
                    started_speaking = True
                silent_chunks = 0
                print(".", end="", flush=True)
            elif started_speaking:
                silent_chunks += 1
                remaining = max(0, SILENCE_DURATION - (silent_chunks * CHUNK / SAMPLE_RATE))
                if remaining > 0:
                    self.ui.show_status(f"ğŸ¤ å½•éŸ³ä¸­... (é™éŸ³ {remaining:.1f}s åç»“æŸ)")

            if started_speaking and silent_chunks > max_silent_chunks:
                print(f"\nâœ“ æ£€æµ‹åˆ° {SILENCE_DURATION} ç§’é™éŸ³ï¼Œåœæ­¢å½•éŸ³")
                self.ui.show_status("âœ“ å½•éŸ³ç»“æŸ")
                break

        if not started_speaking:
            print("\nå½•éŸ³ç»“æŸï¼ˆæœªæ£€æµ‹åˆ°å£°éŸ³ï¼‰")
        else:
            print("\nå½•éŸ³ç»“æŸ")

        stream.stop_stream()
        stream.close()
        audio.terminate()

        # ä¿å­˜ä¸º WAV æ–‡ä»¶
        wf = wave.open(filename, 'wb')
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(audio.get_sample_size(pyaudio.paInt16))
        wf.setframerate(SAMPLE_RATE)
        wf.writeframes(b''.join(frames))
        wf.close()

    def transcribe(self, audio_file):
        """ä½¿ç”¨ Whisper è½¬å½•éŸ³é¢‘"""
        self.ui.show_status("â³ æ­£åœ¨è¯†åˆ«...")
        print("\nâ³ æ­£åœ¨è¯†åˆ«...")
        start_time = time.time()

        result = self.model.transcribe(
            audio_file,
            language=LANGUAGE,
            fp16=False
        )
        text = result["text"].strip()

        # ç¹ä½“è½¬ç®€ä½“
        if self.cc and text:
            text = self.cc.convert(text)

        elapsed = time.time() - start_time
        print(f"âœ“ è¯†åˆ«å®Œæˆ (è€—æ—¶ {elapsed:.1f} ç§’)")

        return text

    def copy_to_clipboard(self, text):
        """å°†æ–‡å­—å¤åˆ¶åˆ°å‰ªè´´æ¿"""
        if not text:
            print("æœªè¯†åˆ«åˆ°æ–‡å­—")
            self.ui.show_result("æœªè¯†åˆ«åˆ°æ–‡å­—", success=False)
            return False

        print(f"\nè¯†åˆ«ç»“æœ: {text}")

        try:
            process = subprocess.Popen(['xclip', '-selection', 'clipboard'],
                                      stdin=subprocess.PIPE)
            process.communicate(input=text.encode('utf-8'))
            print("\nâœ“ å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼Œå¯ä½¿ç”¨ Ctrl+V ç²˜è´´")
            self.ui.show_result(f"{text}\n\nå·²å¤åˆ¶åˆ°å‰ªè´´æ¿", success=True)
            return True
        except FileNotFoundError:
            error_msg = "æœªæ‰¾åˆ° xclip å‘½ä»¤\nè¯·å®‰è£…: sudo apt install xclip"
            print(f"âŒ é”™è¯¯: {error_msg}", file=sys.stderr)
            self.ui.show_error(error_msg)
            return False
        except Exception as e:
            error_msg = f"å¤åˆ¶å¤±è´¥: {e}"
            print(f"âŒ {error_msg}", file=sys.stderr)
            self.ui.show_error(error_msg)
            return False

    def run(self):
        """ä¸»æµç¨‹"""
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            audio_file = tmp_file.name

        total_start = time.time()

        try:
            # 1. å½•éŸ³
            self.record_audio(audio_file)

            # 2. è¯†åˆ«
            text = self.transcribe(audio_file)

            # 3. å¤åˆ¶åˆ°å‰ªè´´æ¿
            self.copy_to_clipboard(text)

            # æ˜¾ç¤ºæ€»è€—æ—¶
            total_elapsed = time.time() - total_start
            print(f"\nâ±ï¸  æ€»è€—æ—¶: {total_elapsed:.1f} ç§’")

            time.sleep(1)

        except KeyboardInterrupt:
            print("\n\nç”¨æˆ·å–æ¶ˆ")
            self.ui.show_error("ç”¨æˆ·å–æ¶ˆ")
            time.sleep(1)
        except Exception as e:
            error_msg = f"å‘ç”Ÿé”™è¯¯: {e}"
            print(f"\nâŒ {error_msg}", file=sys.stderr)
            self.ui.show_error(error_msg)
            time.sleep(2)
        finally:
            if os.path.exists(audio_file):
                os.remove(audio_file)
            self.ui.close()


# ========== å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ ==========
class VoiceInputDaemon:
    """å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ - å¸¸é©»åå°ï¼Œå¿«é€Ÿå“åº”"""

    def __init__(self):
        print("ğŸš€ å¯åŠ¨è¯­éŸ³è¾“å…¥å®ˆæŠ¤è¿›ç¨‹...")
        print(f"â³ æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ ({WHISPER_MODEL})...")
        start_time = time.time()

        self.model = whisper.load_model(WHISPER_MODEL)
        elapsed = time.time() - start_time
        print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶ {elapsed:.1f} ç§’)")

        # åˆå§‹åŒ–ç¹ç®€è½¬æ¢å™¨
        if OPENCC_AVAILABLE:
            self.cc = OpenCC('t2s')
            print("âœ“ ç¹ç®€è½¬æ¢: å·²å¯ç”¨")
        else:
            self.cc = None
            print("âš  ç¹ç®€è½¬æ¢: æœªå¯ç”¨")

        self.socket = None
        self.running = True

        print(f"âœ“ å®ˆæŠ¤è¿›ç¨‹å°±ç»ªï¼Œç­‰å¾…å½•éŸ³è¯·æ±‚...")
        print(f"   Socket: {SOCKET_PATH}")

    def record_audio(self, filename, status_conn=None):
        """å½•åˆ¶éŸ³é¢‘ï¼Œæ£€æµ‹é™éŸ³è‡ªåŠ¨åœæ­¢"""
        audio = pyaudio.PyAudio()

        stream = audio.open(
            format=pyaudio.paInt16,
            channels=CHANNELS,
            rate=SAMPLE_RATE,
            input=True,
            frames_per_buffer=CHUNK
        )

        print(f"\nğŸ¤ å¼€å§‹å½•éŸ³... (åœé¡¿{SILENCE_DURATION}ç§’è‡ªåŠ¨ç»“æŸï¼Œæœ€é•¿{RECORD_SECONDS}ç§’)")

        frames = []
        silent_chunks = 0
        max_silent_chunks = int(SILENCE_DURATION * SAMPLE_RATE / CHUNK)
        started_speaking = False

        for i in range(0, int(SAMPLE_RATE / CHUNK * RECORD_SECONDS)):
            data = stream.read(CHUNK)
            frames.append(data)

            audio_data = np.frombuffer(data, dtype=np.int16)
            volume = np.abs(audio_data).mean()

            if volume > SILENCE_THRESHOLD_DAEMON:
                if not started_speaking:
                    print("âœ“ æ£€æµ‹åˆ°å£°éŸ³ï¼Œå¼€å§‹è®°å½•...")
                    started_speaking = True
                    if status_conn:
                        self.send_status(status_conn, "speaking", "âœ“ æ£€æµ‹åˆ°å£°éŸ³ï¼Œå¼€å§‹è®°å½•...")
                silent_chunks = 0
                print(".", end="", flush=True)

                # å®æ—¶å‘é€éŸ³é‡çŠ¶æ€
                if status_conn and i % 10 == 0:
                    volume_percent = min(100, int(volume / 50))
                    self.send_status(status_conn, "recording_active", f"volume:{volume_percent}")

            elif started_speaking:
                silent_chunks += 1
                if status_conn and silent_chunks % 5 == 0:
                    remaining = SILENCE_DURATION - (silent_chunks * CHUNK / SAMPLE_RATE)
                    if remaining > 0:
                        self.send_status(status_conn, "recording_silence", f"silence:{remaining:.1f}")

            if started_speaking and silent_chunks > max_silent_chunks:
                print(f"\nâœ“ æ£€æµ‹åˆ° {SILENCE_DURATION} ç§’é™éŸ³ï¼Œåœæ­¢å½•éŸ³")
                if status_conn:
                    self.send_status(status_conn, "recording_stopped", f"âœ“ æ£€æµ‹åˆ° {SILENCE_DURATION} ç§’é™éŸ³ï¼Œåœæ­¢å½•éŸ³")
                break

        if not started_speaking:
            print("\nå½•éŸ³ç»“æŸï¼ˆæœªæ£€æµ‹åˆ°å£°éŸ³ï¼‰")
        else:
            print("\nå½•éŸ³ç»“æŸ")

        stream.stop_stream()
        stream.close()
        audio.terminate()

        # ä¿å­˜ä¸º WAV æ–‡ä»¶
        wf = wave.open(filename, 'wb')
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(audio.get_sample_size(pyaudio.paInt16))
        wf.setframerate(SAMPLE_RATE)
        wf.writeframes(b''.join(frames))
        wf.close()

    def transcribe(self, audio_file):
        """ä½¿ç”¨ Whisper è½¬å½•éŸ³é¢‘"""
        print("\nâ³ æ­£åœ¨è¯†åˆ«...")
        start_time = time.time()

        result = self.model.transcribe(
            audio_file,
            language=LANGUAGE,
            fp16=False
        )
        text = result["text"].strip()

        # ç¹ä½“è½¬ç®€ä½“
        if self.cc and text:
            text = self.cc.convert(text)

        elapsed = time.time() - start_time
        print(f"âœ“ è¯†åˆ«å®Œæˆ (è€—æ—¶ {elapsed:.1f} ç§’)")

        return text

    def copy_to_clipboard(self, text):
        """å°†æ–‡å­—å¤åˆ¶åˆ°å‰ªè´´æ¿"""
        if not text:
            print("æœªè¯†åˆ«åˆ°æ–‡å­—")
            return False

        print(f"\nè¯†åˆ«ç»“æœ: {text}")

        try:
            process = subprocess.Popen(['xclip', '-selection', 'clipboard'],
                                      stdin=subprocess.PIPE)
            process.communicate(input=text.encode('utf-8'))
            print("\nâœ“ å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼Œå¯ä½¿ç”¨ Ctrl+V ç²˜è´´")
            return True
        except FileNotFoundError:
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ° xclip å‘½ä»¤", file=sys.stderr)
            return False
        except Exception as e:
            print(f"âŒ å¤åˆ¶å¤±è´¥: {e}", file=sys.stderr)
            return False

    def send_status(self, conn, status, message=""):
        """å‘å®¢æˆ·ç«¯å‘é€çŠ¶æ€æ›´æ–°"""
        try:
            data = json.dumps({"status": status, "message": message}) + "\n"
            conn.sendall(data.encode('utf-8'))
        except:
            pass

    def handle_request(self, conn):
        """å¤„ç†ä¸€æ¬¡å½•éŸ³è¯·æ±‚"""
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            audio_file = tmp_file.name

        total_start = time.time()

        try:
            # 1. å½•éŸ³
            self.send_status(conn, "recording", f"ğŸ¤ å¼€å§‹å½•éŸ³...")
            self.record_audio(audio_file, status_conn=conn)

            # 2. è¯†åˆ«
            self.send_status(conn, "recognizing", "â³ æ­£åœ¨è¯†åˆ«...")
            text = self.transcribe(audio_file)

            # 3. å¤åˆ¶åˆ°å‰ªè´´æ¿
            if text:
                self.send_status(conn, "copying", f"ğŸ“‹ è¯†åˆ«ç»“æœ: {text}")
                self.copy_to_clipboard(text)

                total_elapsed = time.time() - total_start
                self.send_status(conn, "done", f"âœ“ å®Œæˆï¼æ€»è€—æ—¶: {total_elapsed:.1f}ç§’")
            else:
                self.send_status(conn, "done", "âš ï¸ æœªè¯†åˆ«åˆ°æ–‡å­—")

            return True
        except Exception as e:
            self.send_status(conn, "error", f"âŒ é”™è¯¯: {e}")
            print(f"\nâŒ å¤„ç†è¯·æ±‚å¤±è´¥: {e}", file=sys.stderr)
            return False
        finally:
            if os.path.exists(audio_file):
                os.remove(audio_file)

    def start_server(self):
        """å¯åŠ¨ Socket æœåŠ¡å™¨"""
        # æ¸…ç†æ—§çš„ socket æ–‡ä»¶
        if os.path.exists(SOCKET_PATH):
            os.remove(SOCKET_PATH)

        # åˆ›å»º Unix Domain Socket
        self.socket = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
        self.socket.bind(SOCKET_PATH)
        self.socket.listen(1)

        # è®¾ç½®æ–‡ä»¶æƒé™
        os.chmod(SOCKET_PATH, 0o600)

        print(f"âœ“ Socket æœåŠ¡å™¨å·²å¯åŠ¨")
        print(f"âœ“ å®ˆæŠ¤è¿›ç¨‹è¿è¡Œä¸­ï¼ŒæŒ‰ Ctrl+C é€€å‡º\n")

        while self.running:
            try:
                # ä½¿ç”¨ select ç­‰å¾…è¿æ¥
                readable, _, _ = select.select([self.socket], [], [], 1.0)

                if not readable:
                    continue

                conn, addr = self.socket.accept()

                print(f"\n{'='*60}")
                print(f"ğŸ“¥ æ”¶åˆ°å½•éŸ³è¯·æ±‚ ({time.strftime('%H:%M:%S')})")
                print(f"{'='*60}")

                try:
                    self.handle_request(conn)
                finally:
                    try:
                        conn.close()
                    except:
                        pass

                print(f"\n{'='*60}")
                print(f"âœ“ è¯·æ±‚å¤„ç†å®Œæˆï¼Œç­‰å¾…ä¸‹æ¬¡å½•éŸ³...")
                print(f"{'='*60}\n")

            except KeyboardInterrupt:
                print("\n\næ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
                break
            except Exception as e:
                print(f"\nâŒ Socket é”™è¯¯: {e}", file=sys.stderr)

    def shutdown(self):
        """å…³é—­å®ˆæŠ¤è¿›ç¨‹"""
        self.running = False
        if self.socket:
            self.socket.close()
        if os.path.exists(SOCKET_PATH):
            os.remove(SOCKET_PATH)
        print("âœ“ å®ˆæŠ¤è¿›ç¨‹å·²å…³é—­")


# ========== è§¦å‘å™¨æ¨¡å¼ ==========
def draw_volume_bar(volume_percent):
    """ç»˜åˆ¶éŸ³é‡æ¡"""
    bar_length = 30
    filled = int(bar_length * volume_percent / 100)
    bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
    return f"ğŸ¤ [{bar}] {volume_percent}%"


def trigger_daemon():
    """è§¦å‘å®ˆæŠ¤è¿›ç¨‹æ‰§è¡Œå½•éŸ³"""
    ui = VoiceInputUI(mode="auto", title="è¯­éŸ³è¾“å…¥ (å¿«é€Ÿæ¨¡å¼)", borderless=True)

    if not os.path.exists(SOCKET_PATH):
        error_msg = "å®ˆæŠ¤è¿›ç¨‹æœªè¿è¡Œ\nè¯·å…ˆè¿è¡Œ: python voice_input.py --daemon"
        print(f"âŒ {error_msg}")
        ui.show_error(error_msg)
        time.sleep(2)
        ui.close()
        return False

    try:
        # è¿æ¥åˆ°å®ˆæŠ¤è¿›ç¨‹
        ui.show_status("â³ è¿æ¥å®ˆæŠ¤è¿›ç¨‹...")
        sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
        sock.connect(SOCKET_PATH)

        print("âœ“ å·²è¿æ¥åˆ°å®ˆæŠ¤è¿›ç¨‹\n")
        ui.show_status("ğŸ¤ æ­£åœ¨å½•éŸ³...")

        # å‘é€è¯·æ±‚
        sock.sendall(b"RECORD")

        # æ¥æ”¶å¹¶æ˜¾ç¤ºçŠ¶æ€æ›´æ–°
        buffer = ""
        recording_active = False

        while True:
            try:
                data = sock.recv(1024)
                if not data:
                    break

                buffer += data.decode('utf-8')

                # å¤„ç†å®Œæ•´çš„ JSON è¡Œ
                while '\n' in buffer:
                    line, buffer = buffer.split('\n', 1)
                    if line.strip():
                        try:
                            status_data = json.loads(line)
                            message = status_data.get('message', '')
                            status = status_data.get('status', '')

                            if status == 'recording_active':
                                if ':' in message:
                                    volume = int(message.split(':')[1])
                                    ui.update_volume(volume)
                                    volume_bar = draw_volume_bar(volume)
                                    print(f"\r{volume_bar}", end="", flush=True)
                                    recording_active = True

                            elif status == 'recording_silence':
                                if ':' in message:
                                    remaining = message.split(':')[1]
                                    ui.show_status(f"ğŸ¤ å½•éŸ³ä¸­... (é™éŸ³ {remaining}s åç»“æŸ)")
                                    print(f"\râ¸ï¸  é™éŸ³æ£€æµ‹ä¸­... è¿˜å‰© {remaining} ç§’", end="", flush=True)

                            elif status == 'speaking':
                                if recording_active:
                                    print()
                                ui.show_status("ğŸ¤ æ­£åœ¨å½•éŸ³... (æ£€æµ‹åˆ°å£°éŸ³)")
                                print(message)
                                recording_active = True

                            elif status == 'recording_stopped':
                                if recording_active:
                                    print()
                                ui.show_status("âœ“ å½•éŸ³ç»“æŸ")
                                print(message)
                                recording_active = False

                            elif status in ['recording', 'recognizing', 'copying']:
                                if recording_active:
                                    print()
                                    recording_active = False
                                if status == 'recognizing':
                                    ui.show_status("â³ æ­£åœ¨è¯†åˆ«...")
                                elif status == 'copying':
                                    ui.show_status("âœ“ æ­£åœ¨å¤åˆ¶...")
                                print(message)

                            elif status in ['done', 'error']:
                                if recording_active:
                                    print()
                                print(message)

                                if status == 'done':
                                    ui.show_result(message, success=True)
                                    time.sleep(1)
                                else:
                                    ui.show_error(message)
                                    time.sleep(2)

                                ui.close()
                                sock.close()
                                return status == 'done'

                            else:
                                if message:
                                    print(message)

                        except json.JSONDecodeError:
                            pass

            except socket.timeout:
                continue
            except Exception as e:
                print(f"\nâŒ æ¥æ”¶çŠ¶æ€æ—¶å‡ºé”™: {e}")
                break

        sock.close()
        ui.close()
        return True

    except ConnectionRefusedError:
        error_msg = "æ— æ³•è¿æ¥åˆ°å®ˆæŠ¤è¿›ç¨‹\nè¯·æ£€æŸ¥å®ˆæŠ¤è¿›ç¨‹æ˜¯å¦æ­£åœ¨è¿è¡Œ"
        print(f"âŒ {error_msg}")
        ui.show_error(error_msg)
        time.sleep(2)
        ui.close()
        return False
    except Exception as e:
        error_msg = f"é”™è¯¯: {e}"
        print(f"âŒ {error_msg}")
        ui.show_error(error_msg)
        time.sleep(2)
        ui.close()
        return False


# ========== ä¿¡å·å¤„ç† ==========
def signal_handler(signum, frame):
    """å¤„ç†ç³»ç»Ÿä¿¡å·"""
    print(f"\næ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨é€€å‡º...")
    sys.exit(0)


# ========== ä¸»å…¥å£ ==========
def main():
    parser = argparse.ArgumentParser(
        description='è¯­éŸ³è¾“å…¥å·¥å…· - åŸºäº OpenAI Whisper ç¦»çº¿è¯†åˆ«',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
è¿è¡Œæ¨¡å¼:
  python voice_input.py          æ™®é€šæ¨¡å¼ (4-5ç§’å¯åŠ¨)
  python voice_input.py --daemon å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ (å¸¸é©»åå°)
  python voice_input.py --trigger è§¦å‘å®ˆæŠ¤è¿›ç¨‹ (<0.5ç§’å¯åŠ¨)

å¿«æ·é”®å»ºè®®: Super+V
        '''
    )

    group = parser.add_mutually_exclusive_group()
    group.add_argument('--daemon', action='store_true',
                      help='å¯åŠ¨å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ï¼ˆå¸¸é©»åå°ï¼Œé¢„åŠ è½½æ¨¡å‹ï¼‰')
    group.add_argument('--trigger', action='store_true',
                      help='è§¦å‘å®ˆæŠ¤è¿›ç¨‹æ‰§è¡Œå½•éŸ³ï¼ˆéœ€è¦å…ˆå¯åŠ¨å®ˆæŠ¤è¿›ç¨‹ï¼‰')

    args = parser.parse_args()

    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        if args.daemon:
            # å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼
            daemon = VoiceInputDaemon()
            try:
                daemon.start_server()
            except Exception as e:
                print(f"\nâŒ å®ˆæŠ¤è¿›ç¨‹é”™è¯¯: {e}", file=sys.stderr)
                daemon.shutdown()
                sys.exit(1)
            finally:
                daemon.shutdown()

        elif args.trigger:
            # è§¦å‘å™¨æ¨¡å¼
            success = trigger_daemon()
            sys.exit(0 if success else 1)

        else:
            # æ™®é€šæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
            voice = VoiceInputNormal()
            voice.run()

    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·å–æ¶ˆ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
