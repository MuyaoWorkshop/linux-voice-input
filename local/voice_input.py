#!/usr/bin/env python3
"""
è¯­éŸ³è¾“å…¥å·¥å…· - åŸºäº OpenAI Whisper
ä½¿ç”¨éº¦å…‹é£å½•éŸ³ï¼Œè½¬æ¢ä¸ºæ–‡å­—åå¤åˆ¶åˆ°å‰ªè´´æ¿
"""

import whisper
import pyaudio
import wave
import tempfile
import os
import subprocess
import sys

# é…ç½®å‚æ•°
WHISPER_MODEL = "base"  # å¯é€‰: tiny, base, small, medium, large
LANGUAGE = "zh"         # ä¸­æ–‡è¯†åˆ«
SAMPLE_RATE = 16000     # é‡‡æ ·ç‡
CHANNELS = 1            # å•å£°é“
CHUNK = 1024            # éŸ³é¢‘å—å¤§å°
RECORD_SECONDS = 10     # æœ€é•¿å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
SILENCE_THRESHOLD = 500 # é™éŸ³é˜ˆå€¼ï¼ˆå¯è°ƒæ•´ï¼‰
SILENCE_DURATION = 2.0  # é™éŸ³æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰åˆ¤å®šä¸ºç»“æŸ

class VoiceInput:
    def __init__(self):
        print("æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹...")
        self.model = whisper.load_model(WHISPER_MODEL)
        print(f"æ¨¡å‹åŠ è½½å®Œæˆ: {WHISPER_MODEL}")

    def record_audio(self, filename):
        """å½•åˆ¶éŸ³é¢‘ï¼Œæ£€æµ‹é™éŸ³è‡ªåŠ¨åœæ­¢"""
        audio = pyaudio.PyAudio()

        # æ‰“å¼€éŸ³é¢‘æµ
        stream = audio.open(
            format=pyaudio.paInt16,
            channels=CHANNELS,
            rate=SAMPLE_RATE,
            input=True,
            frames_per_buffer=CHUNK
        )

        print("\nğŸ¤ å¼€å§‹å½•éŸ³... (è¯´è¯ååœé¡¿2ç§’è‡ªåŠ¨ç»“æŸ)")

        frames = []
        silent_chunks = 0
        max_silent_chunks = int(SILENCE_DURATION * SAMPLE_RATE / CHUNK)
        started_speaking = False

        for i in range(0, int(SAMPLE_RATE / CHUNK * RECORD_SECONDS)):
            data = stream.read(CHUNK)
            frames.append(data)

            # è®¡ç®—éŸ³é‡
            audio_data = list(data)
            if len(audio_data) > 0:
                volume = sum(abs(b) for b in audio_data) / len(audio_data)

                if volume > SILENCE_THRESHOLD:
                    started_speaking = True
                    silent_chunks = 0
                    print(".", end="", flush=True)
                elif started_speaking:
                    silent_chunks += 1

                # å¦‚æœå·²ç»å¼€å§‹è¯´è¯ï¼Œä¸”é™éŸ³è¶…è¿‡é˜ˆå€¼ï¼Œåœæ­¢å½•éŸ³
                if started_speaking and silent_chunks > max_silent_chunks:
                    print("\næ£€æµ‹åˆ°é™éŸ³ï¼Œåœæ­¢å½•éŸ³")
                    break

        print("\nå½•éŸ³ç»“æŸ")

        # åœæ­¢å¹¶å…³é—­æµ
        stream.stop_stream()
        stream.close()
        audio.terminate()

        # ä¿å­˜ä¸º WAV æ–‡ä»¶
        wf = wave.open(filename, 'wb')
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(audio.get_sample_size(pyaudio.paInt16))
        wf.setframerate(SAMPLE_RATE)
        wf.writeframes(b''.join(frames))
        wf.close()

    def transcribe(self, audio_file):
        """ä½¿ç”¨ Whisper è½¬å½•éŸ³é¢‘"""
        print("æ­£åœ¨è¯†åˆ«...")
        result = self.model.transcribe(
            audio_file,
            language=LANGUAGE,
            fp16=False  # CPU æ¨¡å¼å¿…é¡»è®¾ä¸º False
        )
        return result["text"].strip()

    def copy_to_clipboard(self, text):
        """å°†æ–‡å­—å¤åˆ¶åˆ°å‰ªè´´æ¿"""
        if not text:
            print("æœªè¯†åˆ«åˆ°æ–‡å­—")
            return

        print(f"\nè¯†åˆ«ç»“æœ: {text}")

        try:
            # å°†æ–‡å­—å¤åˆ¶åˆ°å‰ªè´´æ¿
            process = subprocess.Popen(['xclip', '-selection', 'clipboard'],
                                      stdin=subprocess.PIPE)
            process.communicate(input=text.encode('utf-8'))
            print("\nâœ“ å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼Œå¯ä½¿ç”¨ Ctrl+V ç²˜è´´")

        except FileNotFoundError:
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ° xclip å‘½ä»¤ï¼Œè¯·å®‰è£…: sudo apt install xclip", file=sys.stderr)
        except Exception as e:
            print(f"âŒ å¤åˆ¶å¤±è´¥: {e}", file=sys.stderr)

    def run(self):
        """ä¸»æµç¨‹"""
        # åˆ›å»ºä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            audio_file = tmp_file.name

        try:
            # 1. å½•éŸ³
            self.record_audio(audio_file)

            # 2. è¯†åˆ«
            text = self.transcribe(audio_file)

            # 3. å¤åˆ¶åˆ°å‰ªè´´æ¿
            self.copy_to_clipboard(text)

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(audio_file):
                os.remove(audio_file)

def main():
    try:
        voice_input = VoiceInput()
        voice_input.run()
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·å–æ¶ˆ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    main()
